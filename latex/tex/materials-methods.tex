%Tutkimusaineisto ja -menetelm√§t
\section{3D scanning rig implementation}

\subsection{Functional specification} % {{{

The implementation was specified to be easy to use, portable, flexible and available for both 3D and 4D cases, 4D being a nice-to-have feature.
Portability and open design was also considered to be important.
By documenting the selected hardware and its structure, and writing control code in a generic way, it is hoped that the design could be reimplemented and/or refined by others too.

There is a wide variety of different consumer grade digital cameras.
Some of the main differences are dicussed below.

% }}}

\subsubsection{Features} % {{{

Some of the above stuff goes here

% }}}

\subsubsection{Practicalities} % {{{

A general-purpose reconstruction rig has remarkably many practical matters to consider when comparing to the pure mathematical side.
A mobile rig should be light enough to carry and set up, but it should be rigid enough to give proper quality pictures and hold its calibrated configuration.
Distance to the photographed target should not be too short in order to not annoy human targets, but a too large setup is difficult to build and needs lots of space.
When capturing video, the frames should be synchronized among cameras as described in \ref{sec:somethingaboutvideosync}, which might not be possible with a reasonable budget.

% or \subsection{Data recording}

- lens distortion?
- rigid base, motion blur
- baseline width, focus, depth, fstop etc
- compression artifacts are nasty (edge detectors go wild etc.)

% }}}

\subsection{Camera comparison} % {{{

not considered: weatherproofing, lcd/viewfinder/user interface, mirror blackout, autofocus, etc

The section \ref{sec:cameratypes} presents in more detail the properties necessary for reconstruction.

Reliability on configurability and controllability was considered important.
Cheaper cameras fit more into a budget, but they might not be properly controllable.
External shutter release mechanisms have been researched more on DSLRs;
the manufacturers do not provide official specifications of the release connector pinouts, but they have been reverse-engineered for many models by individual tinkerers.
Zoom-only lenses and lack of raw processing, fast processors, manual modes etc.~leave cheaper compact cameras out of the comparison.
More expensive models do have comparable features, but their prices rise into the same range as with DSLRs that are more understood.

Canon DSLRs have been used previously on commercial setups [infiniterealities, ten24, capture lab likeness capture rig (ea sports/fifa example), remedy].
Commercial video capture setups use specialized machine vision devices and partly custom software to export data into suitable format.

Machine vision devices need several high performance computers for reliable multi-camera capture.
Where each camera outputs approximately 1 Gbit/s of data, approximately one hard disk per camera is needed if the capture is long enough and does not fit in a computer's RAM, increasing the system cost and complexity.
Best mechanical hard disks have sequential write speed that just exceeds 1 Gbit/s;
newer solid-state disks (SSD) generally are two to four times faster.

For covering all the bandwidth, an expansion card would be needed per camera, count depending on the camera protocol. According to specifications, USB 3.0 has a maximum transmission rate of 5 Gbit/s, Camera Link supports 5.44 Gbit/s in base and full configuration, FireWire up to 3,2 Gbit/s and GigE only 1 Gbit/s.
Additionally, actual data transfer speeds are less than the theoretical max rate advertised because of protocol and operating system overhead.
Most PC motherboards can accommodate only a few cards, requiring several PCs.

\begin{itemize}
\item CMOS/CCD sensor. CMOS suffers from rolling shutter in video mode, while CCD is more expensive and rare.
\item Resolution and sensor size. Higher resolution covers more detail, until airy disk size is reached. Larger sensor is more sensitive to light and therefore results in lower noise.
\item Lens quality. High resolution is only useful if the lens is sharp enough to fully use the pixel count.
\item Dynamic range, i.e. bit depth of the processing pipeline. JPEG pictures have only 8 bits per color channel, whereas DSLRs and industrial cameras use more, often 12 to 14 bits per pixel (in raw image, that contains the raw bayer pattern before interpolation)
\item Continuous speed. Controlled by many factors, the rate at which full-size pictures can be taken; image processing speed and memory card write speed have most effect.
\item Dust reduction. If enabled for some consumer cameras, it is implemented as high-frequency vibration of the sensor on camera bootup. Because it moves the sensor, it may affect calibration. (Not sure.)
\item Optical stabilization works by moving a glass element inside the lens or the sensor itself, effectively moving the image on the sensor, having a bad effect on calibration.
\item Video frame rate, resolution and compression. Cameras that support raw usually only use raw for still pictures and compress the video, as raw video is often unnecessary in the consumer market and uses lots of space. For image processing, each frame should be as little compressed as possible. Some DSLRs support ALL-I format, which contains only full keyframes (still compressed, but not predicted from other actual frames).
\item Usb speed. Retrieving saved image or video data takes less time for faster interfaces.
\item External flash. Practically all system cameras can be wired to an external flash lamp; only some compact cameras support this. Industrial cameras are externally triggered and require custom wiring.
\item Shutter lag. Lag measured between ordering the camera to take the picture to the actual moment where exposure starts should be consistent, and preferably small.
\item Weight and size. A smaller and lighter camera requires less bulky support structures.
\item Price. With a fixed budget, cheaper cameras can cover a larger area of the subject at a time because more cameras fit in the budget.
\item Availability. For an easily replicable system, it should be simple to purchase the hardware.
\item Configurability. Obviously, aperture, shutter speed and others should be manually controllable and repeatable without automatic features.
\item Low noise. Sensor noise shows immediately in the image quality, complicating correspondence and others.
\end{itemize}

% }}}

Prices for compact cameras that have the required features go up to the same price range as DSLRs or even higher, i.e. 500 EUR and up.

\subsection{Selected cameras} % {{{

%The camera was selected based on 
Precise information on all hardware used can be found in appendix \ref{app:hardwareused}.

\subsubsection{Canon EOS 700D DSLR}

Canon EOS 700D body (or Rebel T5i in US) is among the newest of Canon's consumer range, with a price at about 600EUR.
Key features important for reconstruction are:

\begin{itemize}
	\item 18 Mpix APS-C sized (22.3 x 14.9 mm, or 1.62 crop factor) CMOS sensor, with about 4,3 x 4,3 $\text{\si\micro m}$ pixel size
	\item 14-bit DIGIC 5 processor
	\item Continuous shooting at 5 frames per second
	\item 1080p30 or 720p60 video recording
\end{itemize}

Large pixel count combined to a sharp lens is useful in bringing in a lot of detail.
The sensor's pixel size is not unnecessarily small but not as large as in full frame cameras.
High dynamic range with 14 bits per pixel is more than enough, as most reconstruction programs use 8-bit JPEG images.
The 5 fps continuous speed for full-size images can be used for testing high resolution motion, but the video abilities should be reasonable for motion testing.
Raw video recording should be also possible. % TODO: test this

The sensor is labeled ``Hybrid CMOS'', a new Canon's technology that embeds phase-detection autofocus pixels in the sensor for fast continuous autofocusing in video mode.

The camera also features a tilting LCD screen that has provided to be useful when looking the camera from the front.

An important consideration was the ability to use the third-party Magic Lantern firmware add-on;
it was originally designed for improved user interfaces for video recording, but has been extended for other features too.
Firstly, it provides experimental support for raw video recording and other hacks; additionally, being open source, it can be modified for any custom purposes, such as multi-camera synchronization aids.

The camera uses SD cards for mass storage. A high-speed class 10 UHS-I card was selected; manufacturer claims 45 MB/s write speed.

Additionally, AC power adapters were chosen to operate the cameras without the need for charging batteries.
Canon sells adapters that plug in the camera's battery holder, providing continuous power at the expense of an additional cable per camera.

\subsubsection{Canon EF 50mm f/1.8 II}

Canon's EF mount 50mm f/1.8 II lens (priced at about 110EUR) is commonly known for its excellent, sharp image quality at a low price.
Its build quality is poor and mostly plastic, which may not please professional photographers, but does not matter for laboratory environment.

% }}}

\subsection{Hardware construction} % {{{

\subsubsection{Specified requirements}

\subsubsection{Mechanical structure}

Aluminium profile system as a frame

Generic camera support screws, 360 angle ball joints?

Adapters for machine vision cameras

Arduino-like adapter HW for sync signals

Connectors, wire

% }}}

\subsection{Remote shutter synchronization} % {{{

% }}}

\subsubsection{Canon remote trigger} % {{{

The selected Canon EOS 700D has an input port for focus and shutter release, in addition to the integrated shutter button.
The camera uses a standard 2,5 mm sized stero jack for connecting external remote controllers.
Both mechanical and electronical remotes in wired and wireless format are available in the market, but no standard devices for triggering several cameras seem to exist.
Fortunately, the triggering method is widely researched among hobbyists; it is well enough documented in the internet.

The remote release jack is a three-contact connector, where one pin serves as a common ground, and connecting one pin to the ground triggers the camera's focus button, and the third pin releases the shutter when connected to the ground.
Luk from doc-diy.net [?] describes the camera's trigger circuit internals; the wires supply some current, which is why it's not a good idea to simply connect the remote wires of all cameras together.
A commonly used method among the DIY community is to use opto-isolators to control each camera individually, isolated from the shared control circuit.

An opto-isolator provides a galvanically separated switch that can be used to ``connect'' the release wire to the camera's ground such that no electrical signal path is shared between the cameras.
The switch is commonly a phototransistor that is triggered externally by the light transmitted from a LED.
Both the phototransistor and the LED are installed in a opaque plastic housing.
The opto-isolator device used in this work is shown in figure \ref{fig:opto-isolator}.

% TODO: fig:opto-isolator in physical form and in a schematic diagram next to each other

% }}}

\subsubsection{Synchronized multi-trigger implementation} % {{{

By connecting each camera to a separate opto-isolator and driving all them from a same source, all cameras can be triggered simultaneously in a safe fashion.
To fully automate the system, the trigger device should be connected to the computer that downloads the photos from the cameras.
In this work, a microcontroller prototyping platform called Nucleo-F401RE by STMicroelectronics was used.
This platform has a built-in USB port for simple communication.

A microcontroller is a tiny computer in a single, usually thumb-sized package containing processor, RAM, program memory and peripherals; all parts required to run a single user-defined application often with no general operating system.
The popular Arduino microcontroller board is a popular example of a small-sized microcontroller.

A microcontroller was chosen over e.g. a computer-controlled relay board because its flexibility and low price.
On one hand, such a device is more complicated to set up than a simple switch, but on the other hand, it can be programmed to sequence the cameras in any arbitrary order.
It can also be used to measure the shutter delay and the actual precise time when each camera takes the picture; each has small unpredictable variations.
When capturing moving targets, measuring this lag variation could be of interest.

The Nucleo-F401RE is a prototyping board designed around the STM32F401RET6 microcontroller IC.
This microcontroller ccontains a relatively powerful 32-bit ARM core, space for 512 KB of program code, 96 KB of RAM, 81 I/O pins, and lots of high-performance peripherals not needed in this circuit.

% }}}

\subsection{Custom written software} % {{{

Parallelized image acquisition from a large set of cameras has not yet established such a state that general purpose software would be easily available.
Commercial solutions probably exist, but they are often strictly bound to a specific hardware, costly and inflexible.

Some custom techniques were used to preview images of all cameras simultaneously, configure the settings of each in parallel, and retrieve the captured images from them in order.

% }}}

\subsubsection{Camera control} % {{{

gphoto2 \cite{gphoto2} is a well-known free application and library for controlling digital cameras on Unix-like operating systems, supporting over a thousand cameras.
Instead of relying on each camera manufacturer separately for a software development kit, gphoto2 abstracts common operations behind the same interface.
For example, Canon \cite{canonsdk} and Nikon \cite{nikonsdk}, some of the biggest camera manufacturers, both provide SDKs for controlling their devices remotely.
To support both vendors, one would have to write code for both APIs.
API restrictions, licenses blahblah.

Most modern USB cameras use the Picture Transfer Protocol (PTP) \cite{ptpTODO} for setting properties and transferring pictures, which is also what gphoto2 implements.

It turns out that gphoto2's most thorough support is implemented for Canon and Nikon cameras.

% }}}

\subsubsection{Previewing and configuration} % {{{

Because of the flexible nature of the rig purposes, a simple preview live feed is almost mandatory to properly set up a new configuration.
A preview matrix of all cameras makes it easy to identify the cameras and to point them to correct direction, and to verify that their settings are the same (e.g. similar brightness in preview video).
Remote control of all cameras enables to set all settings, such as shutter speed and focus distance, jointly from the same computer instead of clicking on each camera's buttons manually.


% }}}

\subsubsection{Image acquisition} % {{{

The cameras cannot be triggered individually via USB even though it is possible, because it is too complex and undeterministic for multi-camera synchronization.
Instead, the remote release device is triggered via USB that then releases all shutters at the needed precision.

A custom gphoto2-based software is used to download pictures from the cameras. They are able to automatically notify about new files, which are then downloaded in proper locations via USB.

Guidelines for successful pictures/video

% }}}

\subsection{3D reconstruction software survey} % {{{

 There is a wide collection of libraries, open-source tools and commercial packages for both automatic reconstruction and generic mesh editing for post-processing the data.
 % }}}

\subsubsection{Free libraries} % {{{

There exist several generic computer vision and geometry processing libraries, most common of them being probably OpenCV \cite{opencv}, Point Cloud Library (PCL) \cite{pcl} and Computational Geometry Algorithms Library (CGAL) \cite{cgal}. These are written in the C or C++ languages and they have bindings to several scripting languages too.

OpenCV contains a large set of tools for 2D image processing and extends also to camera calibration and 3D reprojection.
It is probably the most commonly known and most used computer vision algorithm package.

PCL contains a set of algorithms for filtering, segmentation, registration, visualization, and more for working on data sets that consist of points that may share attributes such as colors and normals. CGAL's scope is in the same field, concentrating on a little more advanced topics.

% }}}

\subsubsection{Free programs} % {{{

While libraries can be used to write new tools, many pieces of software are readily available that implement the algorithms presented and are distributed in source code form and/or readily usable binary executables.

Camera Calibration Toolbox for Matlab, also included in OpenCV as a C port, is a more or less standard tool to computation of undistortion maps and intrinsic and extrinsic parameters with checkerboard images using non-linear optimization and homographies. \cite{camcalmatlab}

Bundler is a bundle adjustment and structure-from-motion system for computing camera poses and sparse point clouds. \cite{snavely2006photo}

SiftGPU, a SIFT implementation for graphics processing units. \cite{changchang2007siftgpu} It is built on Sift++ \cite{vedaldi2011sift++}; both are based on difference of gaussians, a method for edge detection \cite{marr1980theory}

Multicore (parallel) bundle adjustment: PBA computes the bundle step in a way that exploits the modern parallel nature of computer processors that have several computing cores. \cite{wu2011multicore}

Patch-based, clustering multi-view stereopsis (PMVS/CMVS) starts from a set of matching keypoints (features) and expands them to a dense patch set iteratively. \cite{furukawa2010accurate,furukawa2012patch}

VisualSFM \cite{wu2013towards} is a common and free but closed-source integration tool simplifying the workflow using external programs.

Meshlab \cite{meshlab} is a portable editor of point clouds and meshes.
It can be used interactively and scripted to do the same steps automatically.
In a reconstruction pipeline, it is one of the last processing steps, used for removing outliers or fitting a surface on a point cloud with the poisson surface reconstruction method, and finally projecting the textures to the generated mesh when given the camera parameters in relation to the point cloud pose.
It can also perform registration between point clouds.

Screened poisson surface reconstruction, or PoissonRecon, is another stand-alone program as an alternative for surface fitting. \cite{kazhdan2013screened}

Cmpmvs is a multi-view reconstruction software for transforming a set of calibrated image data to a full textured mesh, used in a similar way as VisualSFM but using internally a different method based on graph cuts and weakly-supported surfaces.
\cite{jancosek2011multi}

Python Photogrammetry Toolbox is another pipeline combinator for full 3D reconstruction, popular in archaeological fields. It combines Bundler and PMVS and others. \cite{moulon2011python}

VisualSFM is probably the most common tool in the open source community.
It integrates into a few clicks the pipeline from images to 3D point cloud, using SiftGPU for features, PBA for camera estimation, and PMVS/CMVS for dense matching.
A common post step is to use Meshlab to filter outliers away from the data and to build a triangular textured mesh of it with the input points and normals.

%(VisualSFM screenshot here)

% }}}

\subsubsection{Commercial programs} % {{{

There is a large selection of commercial solutions available. Some companies are devoted to building software on certain applications or constructing whole scanning rigs. Examples include:
\begin{description}
\item[Autodesk 123D Catch] is a free web-based application for automatic structureless reconstruction.
\item[CaptiveMotion] provides a facial capture and retargeting system that can be used with full-body mocap.
\item[MotionScan] is the technology behind the video game L.A. Noire. \cite{rockstar2011noire} It uses tens of cameras to recover detailed structure.
\item[Faceshift] encodes a markerless face captuer in a feature space that describes virtual muscle and bone movements.
\item[3DF Zephyr Pro] is another automatic photo reconstruction system.
\item[Mova Contour Reality Capture] does high-performance surface capture with a large array of cameras.
\item[Pendulum Studio] provides a capture system called Alter Ego that integrates with game engines.
\item[Pix4dMapper] converts aerial images to geometric surface models.
\item[Acute3d] is targeted for large-scale photogrammetry and cultural heritage digitization.
\end{description}

%\subsubsection{Other}

(TODO)

- kinect
- meshmixer
- photofly
- sfm toolkit
- alvar/artoolkit
- agisoft photoscan
- voodoo camera tracker
- faro
- cyberware
- geodetic.com
- v-star
- trimensional
- pix4d
- facade
- canoma
- fuel3d
- ms skynet
- dimensional imaging
- bundler based on photosynth?
- boujou matchmover
- vookat
- syntheye
- pftrack
- 3d-equaliser
- photomodel3d
- janimation head tech
- neven vision
- ppr (osm bundler)
- smart3dcapture
- KLT: http://www.inf.ethz.ch/personal/chzach/opensource.html
- http://slowmovideo.granjow.net/

% }}}

\subsection{Sample reconstruction pipeline} % {{{
%\subsection{Full reconstruction} % {{

Both shape and texture are considered in this work. Only diffuse color (albedo) is of interest; more complex material properties are assumed to be captured in other means and not spatially varying.

Basic uv mapping. Project texture to computed mesh. Somehow use colors and optical flow everywhere...

Postprocessing: remodel the mesh (face), see what it would look like. Refine parameters to get a similar output as in the photos (normal map etc.), backproject. Use colors and highpass them; assume uniform lightning and locally uniform texture color (bradley). (Simply a rendering technique, that level of detail in 3D structure might not be needed).

facial expression space, faceshift, face muscles

KINECT 2 HYBRID SHIT YEA

eigenface / pca / AAM model (?)

poisson surface vs ball pivoting

visual convex hull, bbox for constraining

% }}}

\subsection{Computer requirements} % {{{

any pc will do, the bigger the better

% }}}

